{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2FUdu8Dm92Z/+WkXpKkmz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeanyZoldyck/NameBot/blob/main/NameBotdemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GuxOUPaGdtaC"
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "import numpy as np\n",
        "import random\n",
        "from string import ascii_lowercase as L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ohe(name):\n",
        "    #11 is max\n",
        "    nameVec=[]\n",
        "    tempList=[]\n",
        "    for i in range(len(name)-1):\n",
        "        tempList.append((name[i].lower(),name[i+1]))\n",
        "    for pair in tempList:\n",
        "        try:\n",
        "            nameVec.append((L.index(pair[0])*len(L)+L.index(pair[1]))/(len(L)**2-1))\n",
        "        except ValueError:\n",
        "            input(pair)\n",
        "    return nameVec + [0]*(10-len(nameVec))\n",
        "\n",
        "def CE(Y,Y_pred):\n",
        "    epsilon = 1e-9\n",
        "    return -Y*np.log(Y_pred + epsilon) + (1 - Y)*np.log(1 - Y_pred + epsilon)\n",
        "\n",
        "def dCE(Y,Y_pred):\n",
        "    epsilon = 1e-9\n",
        "    return (-Y/(Y_pred + epsilon)) + (1 - Y)/(1 - Y_pred + epsilon)\n",
        "\n",
        "def MSE(Y,a):\n",
        "    return (Y-a)**2\n",
        "\n",
        "def dMSE(Y,a):\n",
        "    return (a-Y)\n",
        "\n",
        "def ReLu(x):\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "def dReLu(x):\n",
        "    return x>=0\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def dSigmoid(x):\n",
        "    z = sigmoid(x)\n",
        "    return z*(1-z)\n",
        "\n",
        "def invSigmoid(x):\n",
        "    return np.log(x/(1-x))\n",
        "\n",
        "def addMatrix(matrix1, matrix2):\n",
        "    if len(matrix1) != len(matrix2) or len(matrix1[0]) != len(matrix2[0]):\n",
        "        raise ValueError(\"Matrices must have the same dimensions for addition\")\n",
        "    result = [[0 for _ in range(len(matrix1[0]))] for _ in range(len(matrix1))]\n",
        "    for i in range(len(matrix1)):\n",
        "        for j in range(len(matrix1[0])):\n",
        "            result[i][j] = matrix1[i][j] + matrix2[i][j]\n",
        "    return result\n",
        "\n",
        "def scaleMatrix(factor, matrix):\n",
        "    result = [[0 for _ in range(len(matrix[0]))] for _ in range(len(matrix))]\n",
        "    for i in range(len(matrix)):\n",
        "        for j in range(len(matrix[0])):\n",
        "            result[i][j] = matrix[i][j] * factor\n",
        "    return result\n",
        "\n",
        "def oneHot(Y):\n",
        "    oneHotY = np.zeros((Y.size,2))\n",
        "    for i, _ in enumerate(oneHotY):\n",
        "        oneHotY[i][int(Y[i])] = 1\n",
        "    return oneHotY"
      ],
      "metadata": {
        "id": "PwYWOMTxfjNg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCNN:\n",
        "    #asserting input of length 10\n",
        "    def __init__(self, topology, inputDim):\n",
        "        self.W = []\n",
        "        self.B = []\n",
        "        self.N = [[0] * dim for dim in topology]\n",
        "        self.topology = topology # describes hidden layers\n",
        "        self.output = 0\n",
        "\n",
        "        He = lambda n: np.sqrt(2/n)\n",
        "        for layer,dim in enumerate(topology):\n",
        "            w1 = []\n",
        "            b1 = []\n",
        "            if layer == 0:\n",
        "                for _ in range(dim):\n",
        "                    tw=[]\n",
        "                    b1.append(random.gauss(0,0.1))\n",
        "                    for _ in range(inputDim):\n",
        "                        tw.append(random.gauss(0,He(inputDim)))\n",
        "                    w1.append(tw)\n",
        "            else:\n",
        "                #if layer == len(topology)-1: continue\n",
        "                for _ in range(dim):\n",
        "                    tw=[]\n",
        "                    b1.append(random.gauss(0,0.1))\n",
        "                    for _ in range(topology[layer-1]):\n",
        "                        tw.append(random.gauss(0,He(topology[layer-1])))\n",
        "                    w1.append(tw)\n",
        "            self.W.append(w1)\n",
        "            self.B.append(b1)\n",
        "        else:#go again for weights between last hidden layer and output layer\n",
        "            w1 = []\n",
        "            b1 = []\n",
        "            b1.append(random.gauss(0,0.1))\n",
        "            for _ in range(dim):\n",
        "                w1.append(random.gauss(0,He(topology[-1])))\n",
        "            self.W.append([w1])\n",
        "            self.B.append(b1)\n",
        "    def setZero(self):\n",
        "        self.output = 0\n",
        "        self.N = [[0] * dim for dim in self.topology]\n",
        "\n",
        "    def forwardProp(self,IL):\n",
        "        self.setZero()\n",
        "        #j is current layer, k is next layer\n",
        "        for layer,dim in enumerate(self.topology):\n",
        "            if layer == 0:\n",
        "                for k in range(dim):\n",
        "                    for j in range(len(IL)):\n",
        "                        self.N[layer][k] += self.W[layer][k][j]*IL[j]\n",
        "                    self.N[layer][k] += self.B[layer][k]\n",
        "                    self.N[layer][k] = ReLu(self.N[layer][k])\n",
        "            else:\n",
        "                for k in range(dim):\n",
        "                    for j in range(self.topology[layer-1]):\n",
        "                        self.N[layer][k] += self.W[layer][k][j]*self.N[layer-1][j]\n",
        "                    self.N[layer][k] += self.B[layer][k]\n",
        "                    self.N[layer][k] = ReLu(self.N[layer][k])\n",
        "\n",
        "        for i in range(self.topology[-1]):\n",
        "            self.output+=self.N[-1][i]*self.W[-1][0][i]\n",
        "        self.output+=self.B[-1][0]\n",
        "        self.output = sigmoid(self.output)\n",
        "\n",
        "    def predict(self, inp):\n",
        "        self.forwardProp(inp)\n",
        "        return self.output\n",
        "    def print(self):\n",
        "        neur = 0\n",
        "        for layer in self.N:\n",
        "            print(layer)\n",
        "            print()\n",
        "    def printWeights(self):\n",
        "        for i in self.W:\n",
        "            print(i)\n",
        "        print()\n",
        "    def cost(self, Y,a):\n",
        "        return MSE(Y,a)\n",
        "    def dCost(self, Y,a):\n",
        "        return dMSE(Y, a)\n",
        "    def backPropagation(self,Y,X,eta):\n",
        "        #n = len(X)\n",
        "        #C=0\n",
        "        #self.forwardProp(X)\n",
        "        '''\n",
        "        d0 = 0\n",
        "        for i in range(n):\n",
        "            self.forwardProp(X[i])\n",
        "            C += self.cost(Y[i],self.output)/n\n",
        "            d0 += self.dCost(Y[i],self.output)*self.output*(1-self.output)/n\n",
        "        '''\n",
        "        d = [[self.dCost(Y,self.output)*self.output*(1-self.output)]]\n",
        "        C=self.cost(Y,self.output)\n",
        "        shape = [1]+self.topology[::-1]\n",
        "        #print(shape)\n",
        "\n",
        "        for layer,dim in enumerate(shape[1:],start=1):\n",
        "            dL=[0]*dim\n",
        "            for j in range(dim):\n",
        "                for k in range(shape[layer-1]):\n",
        "                    dL[j] += d[-1][k]*self.W[-layer][k][j] * dReLu(self.N[-layer][j])\n",
        "            d.append(dL)\n",
        "        #input()\n",
        "        for layer, weightMatrix in enumerate(self.W[::-1],start=1):\n",
        "            for tLi, wList in enumerate(weightMatrix):\n",
        "                for pLi, _ in enumerate(wList):\n",
        "                    #print(self.topology)\n",
        "                    if layer < len(self.W): self.W[-layer][tLi][pLi] -= eta* d[layer-1][tLi] * self.N[-(layer)][pLi]\n",
        "                    else: self.W[-layer][tLi][pLi] -= eta* d[layer-1][tLi]*X[pLi]\n",
        "                self.B[-layer][tLi] -= eta*d[layer-1][tLi]\n",
        "        #self.printWeights()\n",
        "        #input('done')\n",
        "        #self.forwardProp(X)\n",
        "        #print(self.cost(Y, self.output)-C)\n",
        "    def backPropSGD(self,Y,X,eta):\n",
        "        d0 = 0\n",
        "        dW = [scaleMatrix(0,w) for w in self.W]\n",
        "        dB = [[0 for _ in range(len(dmi))] for dmi in self.B]\n",
        "        shape = [1]+self.topology[::-1]\n",
        "        #C=0\n",
        "        n = len(X)\n",
        "        for i in range(n):\n",
        "            self.forwardProp(X[i])\n",
        "            d0 += self.dCost(Y[i],self.output)*self.output*(1-self.output)\n",
        "            d = [[d0]]\n",
        "            #print(shape)\n",
        "\n",
        "            for layer,dim in enumerate(shape[1:],start=1):\n",
        "                dL=[0]*dim\n",
        "                for j in range(dim):\n",
        "                    for k in range(shape[layer-1]):\n",
        "                        dL[j] += d[-1][k]*self.W[-layer][k][j] * dReLu(self.N[-layer][j])\n",
        "                d.append(dL)\n",
        "\n",
        "            for layer, weightMatrix in enumerate(self.W[::-1],start=1):\n",
        "                for tLi, wList in enumerate(weightMatrix):\n",
        "                    for pLi, _ in enumerate(wList):\n",
        "                        if layer < len(self.W): dW[-layer][tLi][pLi] -= d[layer-1][tLi] * ReLu(self.N[-(layer)][pLi])/n\n",
        "                        else: dW[-layer][tLi][pLi] -= d[layer-1][tLi]*X[i][pLi]/n\n",
        "                    dB[-layer][tLi] -= d[layer-1][tLi]/n\n",
        "\n",
        "\n",
        "        for i,bL in enumerate(self.B):\n",
        "            for j,bias in enumerate(bL):\n",
        "                self.B[i][j] = bias + eta*dB[i][j]\n",
        "\n",
        "        #print(len(self.W),len(self.W[0]))\n",
        "        #print(len(dW),len(self.B[0]))\n",
        "\n",
        "        for i,x in enumerate(self.W):\n",
        "            self.W[i] = addMatrix(x, scaleMatrix(eta,dW[i]))\n",
        "    def backPropagation1(self, Y, X, eta, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8):\n",
        "        #TODO: Adam version of SGD\n",
        "        pass\n",
        "\n",
        "    def train(self, X, Y, lr, epochs, batchSize=1):\n",
        "        avgLoss = -1\n",
        "        possible = [[i,j] for j in range(2) for i in range(2)]\n",
        "        for epoch in range(epochs):\n",
        "            if batchSize==1:\n",
        "                for i in range(0,len(X)):\n",
        "                    # Forward Pass\n",
        "                    self.forwardProp(X[i])\n",
        "\n",
        "                    # Backward Propagation\n",
        "                    self.backPropagation(Y[i],X[i], lr)\n",
        "            else:\n",
        "                for i in range(0,len(X),batchSize):\n",
        "                    # Backward Propagation\n",
        "                    self.backPropSGD(Y[i:i+batchSize],X[i:i+batchSize], lr)\n",
        "            # Print the loss for every 100 epochs\n",
        "            if epoch % 100 == 0:\n",
        "                print(f'\\nEpoch {epoch}, Average Loss: {round(avgLoss,10)}')\n",
        "                avgLoss = 0\n",
        "            avgLoss += self.cost(Y[i],self.output)/100\n",
        "            print(round(avgLoss*(100/(1+epoch%100)),8))\n"
      ],
      "metadata": {
        "id": "2UDPMP_biLEr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "source": [
        "\n",
        "with open(\"names_female.txt\") as w:\n",
        "    femaleNames = map(lambda x: x.replace('\\n',''),w.readlines())\n",
        "    w.close()\n",
        "with open(\"names_male.txt\") as m:\n",
        "    maleNames = map(lambda x: x.replace('\\n',''),m.readlines())\n",
        "    m.close()\n",
        "Z = [[0]+ohe(name) for name in femaleNames]+[[1]+ohe(name) for name in maleNames if len(name) < 11]\n",
        "random.shuffle(Z)\n",
        "Y = [z[0] for z in Z]\n",
        "X = [z[1:] for z in Z]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "W6Z87w4UkU7Y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NameBot = BCNN([16], 10)\n",
        "NameBot.train(X,Y,lr=.05,epochs=150,batchSize=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu8Fsjz41b9l",
        "outputId": "c3facc70-4940-44ac-bdba-63d89fc866f8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0, Average Loss: -1\n",
            "0.27168245\n",
            "0.26930161\n",
            "0.26698991\n",
            "0.26475062\n",
            "0.26257835\n",
            "0.26046734\n",
            "0.2584151\n",
            "0.25641955\n",
            "0.25447763\n",
            "0.25258705\n",
            "0.25074493\n",
            "0.24894928\n",
            "0.24719763\n",
            "0.24548673\n",
            "0.24381515\n",
            "0.24217947\n",
            "0.24057723\n",
            "0.23900629\n",
            "0.23746515\n",
            "0.23595205\n",
            "0.23446567\n",
            "0.23303565\n",
            "0.23165522\n",
            "0.23031907\n",
            "0.22902267\n",
            "0.22776248\n",
            "0.22653495\n",
            "0.22533708\n",
            "0.22416637\n",
            "0.22302049\n",
            "0.22189764\n",
            "0.22079614\n",
            "0.21971461\n",
            "0.21865184\n",
            "0.21760673\n",
            "0.21657831\n",
            "0.21556578\n",
            "0.21456859\n",
            "0.21358599\n",
            "0.21261745\n",
            "0.21166232\n",
            "0.21072003\n",
            "0.20978996\n",
            "0.20887167\n",
            "0.20796479\n",
            "0.20706887\n",
            "0.20618346\n",
            "0.20530832\n",
            "0.20444319\n",
            "0.20358786\n",
            "0.202742\n",
            "0.20190547\n",
            "0.201078\n",
            "0.20025933\n",
            "0.19944924\n",
            "0.19864757\n",
            "0.19785413\n",
            "0.19706868\n",
            "0.19629113\n",
            "0.1955214\n",
            "0.19475927\n",
            "0.19400453\n",
            "0.19325707\n",
            "0.19251677\n",
            "0.1917835\n",
            "0.19105712\n",
            "0.19033748\n",
            "0.18962441\n",
            "0.18891774\n",
            "0.18821729\n",
            "0.18752291\n",
            "0.18683452\n",
            "0.18615201\n",
            "0.18547527\n",
            "0.18480419\n",
            "0.18413872\n",
            "0.18347873\n",
            "0.18282414\n",
            "0.18217483\n",
            "0.18153066\n",
            "0.18089153\n",
            "0.18025732\n",
            "0.17962793\n",
            "0.17900329\n",
            "0.17838329\n",
            "0.17776783\n",
            "0.17715681\n",
            "0.17655014\n",
            "0.17594774\n",
            "0.17534951\n",
            "0.17475538\n",
            "0.17416531\n",
            "0.1735792\n",
            "0.17299697\n",
            "0.17241851\n",
            "0.17184374\n",
            "0.17127252\n",
            "0.17070472\n",
            "0.17014026\n",
            "0.16957902\n",
            "\n",
            "Epoch 100, Average Loss: 0.1695790196\n",
            "0.11321113\n",
            "0.11280887\n",
            "0.11240727\n",
            "0.11200731\n",
            "0.11160868\n",
            "0.11121123\n",
            "0.11081475\n",
            "0.11041906\n",
            "0.11002424\n",
            "0.10963016\n",
            "0.10923665\n",
            "0.10884372\n",
            "0.10845137\n",
            "0.10805951\n",
            "0.10766824\n",
            "0.10727749\n",
            "0.10688729\n",
            "0.1064976\n",
            "0.10610834\n",
            "0.10571944\n",
            "0.10533084\n",
            "0.10494258\n",
            "0.10455467\n",
            "0.10416711\n",
            "0.10377987\n",
            "0.103393\n",
            "0.10300647\n",
            "0.10262024\n",
            "0.10223429\n",
            "0.10184859\n",
            "0.10146311\n",
            "0.10107786\n",
            "0.10069283\n",
            "0.10030804\n",
            "0.09992352\n",
            "0.09953937\n",
            "0.09915561\n",
            "0.09877225\n",
            "0.09838928\n",
            "0.09800669\n",
            "0.09762445\n",
            "0.09724259\n",
            "0.09686121\n",
            "0.09648031\n",
            "0.09609989\n",
            "0.09571993\n",
            "0.09534046\n",
            "0.09496154\n",
            "0.09458318\n",
            "0.09420544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gender(name):\n",
        "  return ['fe',''][round(NameBot.predict(ohe(name)))] + \"male\"\n",
        "gender(\"christina\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r8u3yI872w5K",
        "outputId": "57227e60-9523-43ed-eca4-ed9030dab6a4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'female'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NAMES = ['James/Mary', 'Robert/Patricia', 'John/Jennifer', 'Michael/Linda', 'David/Elizabeth', 'William/Barbara', 'Richard/Susan', 'Joseph/Jessica', 'Thomas/Sarah', 'Christopher/Karen', 'Charles/Lisa', 'Daniel/Nancy', 'Matthew/Betty', 'Anthony/Sandra', 'Mark/Margaret', 'Donald/Ashley', 'Steven/Kimberly', 'Andrew/Emily', 'Paul/Donna', 'Joshua/Michelle', 'Kenneth/Carol', 'Kevin/Amanda', 'Brian/Melissa', 'George/Deborah', 'Timothy/Stephanie', 'Ronald/Dorothy', 'Jason/Rebecca', 'Edward/Sharon', 'Jeffrey/Laura', 'Ryan/Cynthia', 'Jacob/Amy', 'Gary/Kathleen', 'Nicholas/Angela', 'Eric/Shirley', 'Jonathan/Brenda', 'Stephen/Emma', 'Larry/Anna', 'Justin/Pamela', 'Scott/Nicole', 'Brandon/Samantha', 'Benjamin/Katherine', 'Samuel/Christine', 'Gregory/Helen', 'Alexander/Debra', 'Patrick/Rachel', 'Frank/Carolyn', 'Raymond/Janet', 'Jack/Maria', 'Dennis/Catherine', 'Jerry/Heather', 'Tyler/Diane', 'Aaron/Olivia', 'Jose/Julie', 'Adam/Joyce', 'Nathan/Victoria', 'Henry/Ruth', 'Zachary/Virginia', 'Douglas/Lauren', 'Peter/Kelly', 'Kyle/Christina', 'Noah/Joan', 'Ethan/Evelyn', 'Jeremy/Judith', 'Walter/Andrea', 'Christian/Hannah', 'Keith/Megan', 'Roger/Cheryl', 'Terry/Jacqueline', 'Austin/Martha', 'Sean/Madison', 'Gerald/Teresa', 'Carl/Gloria', 'Harold/Sara', 'Dylan/Janice', 'Arthur/Ann', 'Lawrence/Kathryn', 'Jordan/Abigail', 'Jesse/Sophia', 'Bryan/Frances', 'Billy/Jean', 'Bruce/Alice', 'Gabriel/Judy', 'Joe/Isabella', 'Logan/Julia', 'Alan/Grace', 'Juan/Amber', 'Albert/Denise', 'Willie/Danielle', 'Elijah/Marilyn', 'Wayne/Beverly', 'Randy/Charlotte', 'Vincent/Natalie', 'Mason/Theresa', 'Roy/Diana', 'Ralph/Brittany', 'Bobby/Doris', 'Russell/Kayla', 'Bradley/Alexis', 'Philip/Lori', 'Eugene/Marie']\n",
        "right = 0\n",
        "for line in NAMES:\n",
        "  m = line.split('/')[0]\n",
        "  f = line.split('/')[1]\n",
        "  mpred = round(NameBot.predict(ohe(m)))\n",
        "  fpred = round(NameBot.predict(ohe(f)))\n",
        "  right += (mpred and not fpred)\n",
        "  print(mpred,fpred )\n",
        "print(right/len(NAMES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-UoAqaI4SFD",
        "outputId": "bfe5d558-71a3-4b01-f08d-83154bd57e30"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n",
            "1 1\n",
            "1 0\n",
            "0 0\n",
            "0 1\n",
            "1 0\n",
            "0 1\n",
            "1 0\n",
            "1 1\n",
            "0 0\n",
            "0 0\n",
            "0 0\n",
            "0 1\n",
            "0 0\n",
            "0 0\n",
            "0 1\n",
            "1 0\n",
            "0 1\n",
            "0 1\n",
            "1 1\n",
            "0 0\n",
            "0 0\n",
            "1 0\n",
            "0 0\n",
            "0 1\n",
            "1 0\n",
            "0 0\n",
            "0 1\n",
            "0 0\n",
            "1 1\n",
            "0 0\n",
            "0 0\n",
            "0 0\n",
            "1 0\n",
            "0 1\n",
            "1 0\n",
            "0 0\n",
            "1 0\n",
            "1 1\n",
            "0 0\n",
            "0 0\n",
            "1 0\n",
            "0 0\n",
            "0 0\n",
            "0 0\n",
            "1 0\n",
            "0 0\n",
            "0 0\n",
            "0 0\n",
            "1 0\n",
            "1 0\n",
            "1 1\n",
            "1 1\n",
            "0 1\n",
            "0 0\n",
            "0 1\n",
            "0 0\n",
            "1 0\n",
            "1 0\n",
            "1 0\n",
            "1 1\n",
            "1 1\n",
            "0 1\n",
            "1 0\n",
            "0 0\n",
            "1 0\n",
            "1 1\n",
            "1 1\n",
            "1 0\n",
            "1 0\n",
            "0 0\n",
            "0 1\n",
            "0 1\n",
            "1 0\n",
            "1 0\n",
            "0 0\n",
            "1 0\n",
            "1 1\n",
            "1 1\n",
            "0 0\n",
            "1 0\n",
            "0 1\n",
            "1 1\n",
            "1 1\n",
            "0 1\n",
            "1 0\n",
            "0 1\n",
            "1 1\n",
            "0 0\n",
            "1 0\n",
            "1 1\n",
            "0 0\n",
            "0 0\n",
            "1 0\n",
            "1 1\n",
            "1 1\n",
            "0 0\n",
            "0 0\n",
            "1 1\n",
            "1 0\n",
            "0.28\n"
          ]
        }
      ]
    }
  ]
}